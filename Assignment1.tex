\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{latexsym}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{mathtools}
\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}
\usepackage{geometry}
 \geometry{
 a4paper,
 total={170mm,257mm} ,
 left=20mm ,
 top=20mm ,
 }

\title{Assignment1}
\author{Aswin cs19b007, Ajith cs19b014, Aryan cs19b030} 
\date{\today}

\begin{document}

\maketitle

\newpage
\begin{enumerate}
    \item\begin{enumerate}
        \item The general algorithm for heap construction takes O($nlogn$) where n is the number of the nodes in the heap. That approach can be optimised by observing the fact that the leaf nodes need not be  heapified since they follow the heap property (node value should be lesser than the children value since they do not have any children the property is satisfied). 
        
        Since heapify is not required for the leaf nodes, identify the position of the first non-leaf node and perform the heapify operation in the reverse order (heapify the subtree rooted with that node). 
        
        Psuedo code for the above algorithm(minHeap):
        \begin{verbatim}
        ConstructHeap(heap){
            index = (n-1)/2     // last non-leaf node
            for(i=index;i>=0;i--) Heapify(heap,i)
        }
        
        Heapify(heap,i){
            left = 2*i + 1
            right = 2*i + 2
            sm = i      // sm -> smallest
            
            if(left<heap_size & heap[left]<heap[sm]) sm = left 
            
            if(right<heap_size & heap[right]<heap[sm]) sm = right 
            
            if(sm!=i) 
                swap(heap[sm],heap[i])
                // since the smallest node is swapped with parent, 
                the swapped node may not form a heap with it's 
                subtree. So recursively heapify that subtree //
                Heapify(heap,sm) 
            }
        \end{verbatim}
        
        \item The number of leaves in a heap with n nodes is $\lceil n/2 \rceil$ .
        
        Proof : 
        
        Last leaf is nth index, it's parent is at index $\lfloor n/2 \rfloor$ so
        there is no element such that its parent is $\lfloor (n/2 +1) \rfloor$th element.
        Thus leaves are indexed from $\lfloor n/2 \rfloor$ +1 to n.

        Hence, total number of leaves = n - $\lfloor n/2 \rfloor$ = $\lceil n/2 \rceil$.
        
        
        For easier calculations let us assume a complete binary tree of height h. 
        
        The number of nodes n = \(2^{h+1}\) - 1. Each level i contains \(2^i\)
        nodes. The level h contains all leafnodes.
        
        The bottom most level containing \(2^h\) nodes require 0 operations since the leaves follow the heap property. The level before the bottom most level containing \(2^{h-1}\), the nodes may go down by one level. Similarly the $ith$ level from the bottom containing \(2^{h-i}\) nodes may go down by i levels. Computing the no. of steps for the whole heap from bottom to top we get the time complexity as,
        
        \[ T(n) = \sum_{i=0}^{h} i 2^{h-i} = 2^h\sum_{i=0}^{h} i 2^{-i} \leq 2^h\sum_{i=0}^{\infty} i 2^{-i}\]
        
        $\sum_{i=0}^{\infty} i 2^{-i}$ is an AGP. The solution to this infinte AGP is:
        
        \[ \sum_{i=0}^{\infty} i x^{i} = \frac{x}{(1-x)^2} \]
        
        Substituting x = 1/2, in the above equation
        
        \[ \sum_{i=0}^{\infty} i 2^{-i} = \frac{1/2}{(1-1/2)^2} = 2\]
        
        \[ \Rightarrow{T(n) = 2^h\sum_{i=0}^{h} i 2^{-i} \leq 2^h (2) = 2^{h+1}} \]
        
        We know that n = \(2^{h+1}\) - 1,
        
        \[ \Rightarrow{T(n) \leq n+1} \]
        
        So, from the above calculation we can say that time complexity of the above mentioned heap construction algorithm is O($n$).
        
        
    \end{enumerate}
    \item To evaluate a polynomial of degree n in linear time Horner's method can be used. Assume a polynomial $f(x)$ of degree n.
    
    \begin{equation} 
    f(x) = a_nx^n + a_{n-1}x^{n-1} + .... + a_1x + a_0
    \end{equation}
    
    The above equation can also be represented as,
    
    \begin{equation} 
    f(x) = (((a_nx + a_{n-1})x + a_{n-2})x.....)x + a_0
    \end{equation}
    
    From the above representation of the equation $f(x)$ we can observe a way of computation of $f(x)$ which is,
    
    Assume initially, \[ f(x_0) = 0 \]
    Mutiply by $x_0$ and add $a_n$
    \[ f(x_0) = f(x_0)x_0 + a_n \]
    \[ \Rightarrow{f(x_0 = a_n}\]
    
    In each step multiply the equation $f(x_0)$ with $x_0$ and add the next coefficient , in this case it's $a_{n-1}$  \[ f(x_0) = f(x_0)x_0 + a_{n-1}\]
    \[ \Rightarrow{f(x_0) = a_nx_0 + a_{n-1}}\]
    
    Similarly in the next step multiply  with x and add the next coefficient
    \[ f(x_0) = (a_nx_0 + a_{n-1})x_0 + a_{n-2}\]
    \[.\]
    \[.\]
    \[.\]
    \[.\]
    \[ f(x_0) = (((a_nx_0 + a_{n-1})x_0 + a_{n-2})x_0.....)x_0 + a_0 \]
    \[f(x_0) = a_nx_0^n + a_{n-1}x_0^{n-1} + .... + a_1x_0 + a_0\]
    
    In each step we multiply by x and add the next coefficient, we do this n times so the total number of additions and multiplications is 2n.
    \begin{verbatim}
    Pseudo code:
        function = 0
        for(i=0 to n) function = function *x + a[n-i]
    \end{verbatim}
    
    In the above algorithm by differentiating in every step using chain rule, the derivative can be computed.
    \begin{verbatim}
    Pseudo code:
        function=0, derivative=0
        for(i=0 to n) 
            derivative = derivative *x + function
            function = function *x + a[n-i]
    \end{verbatim}
    The derivative also requires n multiplications and n additions.  
    \item \textbf{Heap construction:}
    
    \underline{Loop invariant} - All the indices greater than i(loop variable) heap[i+1..n], before each iteration of heapify follow the heap property.
    
    \underline{Proof of correctness}
    
    Initial step - The loop invariant should be true before the first iteration of the loop. This is true since, the loop starts from the first non-leaf which has all leaf nodes after it. All the leaf nodes satisfy heap property 
    
    To prove - If the loop invariant is true for iteration i, it is true for iteration (i-1).
    
    Given that heap[(i+1)..n] follow the heap property. Iteration i heapifies the $ith$ node by swapping(if necessary) with it's children(2i+1,2i+2) subtree and maybe further swapping in the subtree. Children subtrees follow the heap property since, i $<$ 2i+1, 2i+2 which according to our loop invariant follow the heap property. So, the $ith$ node is heapified with two other heaps(subtree rooted with their children) which follow heap property. Hence after heapifying the $ith$ node now A[i..n] follow the heap property which is the loop invariant for the next iteration. 
    
    Termination - The loop invariant is true on the entire input.
    
    After the loop terminates i=-1, from the loop invariant A[0..n] follow the heap property \textit{(i.e)} the whole input follows the heap property.
    
    \textbf{Polynomial evaluation:}
    
    \underline{Loop invariant} - 
    
    \[ \sum_{k=0}^{i} a_{n-i+k} x^{k}\]
    
    \underline{Proof of correctness :}
    
    Initial condition : y = $f(x_0)$ is initialised to 0 \textit{(i.e)} y = 0
    
    Maintenance : By using the loop invariant after $(i+1)th$ iteration
    
    \[ y = a_{n-(i+1)} + x\sum_{k=0}^{i} a_{n-i+k} x^{k} \]
    
    \[ \Rightarrow{ y = a_{n-(i+1)}x^0 + \sum_{k=0}^{i} a_{n-i+k} x^{k+1} } \]
    
    \[ \Rightarrow{ y = \sum_{k=0}^{i} a_{n-(i+1)+(k+1)} x^{k+1} + a_{n-(i+1)}x^0 } \]
    
    \[ \Rightarrow{ y = \sum_{k=1}^{i+1} a_{n-(i+1)+k} x^{k} + a_{n-(i+1)}x^0 } \]
    
    \[ \Rightarrow{ y = \sum_{k=0}^{i+1} a_{n-(i+1)+k} x^{k} } \]
    
    Termination - The loop terminates after i = n, the loop invariant becomes
    
    \[ y = \sum_{k=0}^{n} a_{k} x^{k}\]
    
    This is the given polynomial equation.
    
    \item Maintain a boolean array isPresent[n] stating whether the position in the permutation is already occapied or not, assuming indexing starts from 1.
    
    We can say that $i_1$ represents the position of 1 in the permutation, since all elements to the left of $i_1$ will be greater than 1. Set isPresent[$i_1$] as true. For the other elements, going from 2 to n, traverse through the permutation till the ($i_k$ + 1)th empty position is found, and place it there. 

    We can say that the number of searches in the permutation till we find the $i_k$th empty spot will be less than or equal to $i_k$ + (k-1), $(\textit{i.e})$ the sum of number of empty positions to be searched + the number of elements already placed in the permutation. We can also say that $i_k$ will be less than or equal to n-k, since it represents the number of elements greater than k, to the left of it, $(\textit{i.e})$ all elements greater than it lies on it's left in the permutation.
     \[T(n) \leq \sum_{i=1}^{n}(i_k + k-1)\]
     \[i_k \leq n-k\]
     \[\Rightarrow T(n) \leq \sum_{i=1}^{n}(n-k + k-1)\]
     \[\Rightarrow T(n) \leq \sum_{i=1}^{n}(n-1)\]
     \[\Rightarrow T(n) \leq (n)(n-1)\]
     \[T(n) = O(n^2)\]
    \textbf{Pseudo-code :}
    \begin{verbatim}
        for(int i=1;i<=n;i++){
            numEmpty = 0
            tempPosition = 0
            while(numEmpty <= inversions[i]){
                tempPosition++
                if(isPresent[tempPosition] == false) numEmpty++
            }
            if(tempPosition > n) return (-1)  //the inversion vector is invalid
            permutation[tempPosition] = i
            isPresent[tempPosition] = true
        }
    \end{verbatim}
    Initial conditions ; \{isPresent[i] = false $\forall$ i $\epsilon$ [1,n]\}
    
    Loop invariants : \{(isPresent[i] $\epsilon$ \{true, false\} $\forall$ i $\epsilon$ [1,n]) $\cap$ (1 $\leq$ tempPosition $\leq$ n) \}
    
    Final conditions : \{isPresent[i] = true $\forall$ i $\epsilon$ [1,n]\}
    
    \underline{Proof of correctness}:
    
    Base case: for n=1, the permutation will be \{1\}, \textit{(i.e)} isPresent[i] = true $\forall$ i $\epsilon$ [1,n]
    
    Inductive hypothesis: for n=k, the permutation given by the inversion vector \{$i_1$,$i_2$,....$i_k$\} can be constructed. 
    
    To prove: for n=k+1, the permutation given by the inversion vector \{$i_1$,$i_2$,....$i_k$,$i_{k+1}$\} can be constructed, given that any permutation of length k can be constructed with it's inversion vector
    
    For a given permutation of length k whose inversion vector is given by \{$j_1$,$j_2$,....$j_k$\}, increase all the elements by 1. The inversion vector will not be affected by this change. Now to construct a permutation given by the inversion vector \{$i_1$,$i_2$,....$i_k$,$i_{k+1}$\}, we take $i_{a+1}$ = $j_a$ $\forall$ a $\epsilon$ [1,k]. To finish the construction, we need to add 1 into the modified permutation of length k. This can be done by shifting all the elements whose index is greater than $i_1$ (since indexing starts at 1) to the right by one position and filling the index $i_1+1$ with 1. This too won't affect the values of the other elements in the inversion vector, since 1 is smaller than all the shifted elements.
    
    Therefore, isPresent[i] $\forall$ i $\epsilon$ [1,n] is true and thus, a permutation can be constructed using its inversion vector.
    
    \item\begin{enumerate}
        \item $M_1$ = max \{$W_1$(i,j,k)\} :
        
        To find the two points(belonging to different arrays) who are the furthest apart, irrespective of the third point.
        \begin{verbatim}
        minValue = min(a[1], b[1], c[1])
        maxValue = max(a[n], b[n], c[n])
        if((minValue == c[1]) and (maxValue == c[n])){ 
        //similarly check for other arrays
            temp1 = max(a[n],b[n]) - c[1]
            temp2 = c[n] - min(a[1],b[1])
            M1 = max(temp1, temp2)
        }else M1 = maxValue - minValue
        \end{verbatim}
        Initial conditions : \{(minValue $\epsilon$ \{a[1], b[1], c[1]\}) $\cap$ (maxValue $\epsilon$ \{a[n], b[n], c[n]\})\} 
        
        Final conditions ; \{M = maxValue - minValue\}
        
        Correctness of the algorithm :
        
        Without loss of generality, we can assume a[1] to be the least of \{a[1], b[1], c[1]\} and c[n] to be the largest of \{a[n], b[n], c[n]\}. a[1] will be the least and c[n] will be the largest element from the set \{a[1..n], b[1..n], c[1..n]\} since a[1] is smaller than the other elements of array 'a', and because a[1] is less than b[1] and c[1], it will be less than the other elements of the array 'b' and 'c'. Similarly, we can say that c[n] will be the largest element. Thus the maximum value of $M_!$ will be achieved at [1,j,n], j $\epsilon$ [1,n]
        and it's value will be c[n] - a[1].
        
        But if both the largest and least element of the set \{a[1..n], b[1..n], c[1..n]\} belong to the same array, assuming it to be 'c' without loss of generality, then $M_1$ will be the larger one of (c[n]-min(a[1],b[1])) and (max(a[n],b[n]) - c[1]) 
        \item$M_2$ = min \{$W_1$(i,j,k)\} : 
        
        To find three points(belonging to different arrays) such that the distance between the largest point and the smallest point is the least among all other pairs.
        \begin{verbatim}
            i=1, j=1, k=1
            while(i,j,k <= n){
                W1 = max(|a[i]-b[j]|, |b[j]-c[k]|, |c[k]-a[i]|)
                minW1 = min(minW1, W1)
                minTemp = min(a[i], b[j], c[k])
                if(minTemp == a[i]) i++
                else if(minTemp == b[j]) j++
                else if(minTemp == c[k]) k++
            }
            M2 = minW1
        \end{verbatim}
        Initial conditions : \{(i=j=k=1) $\cap$ (minW1 = W1[1,1,1])\}
        
        Loop invariants : \{M2 = min(minW1, min(W1[i..n,j..n,k..n]))\}
        
        Final conditions : \{(max(i,j,k) = n+1) $\cap$ (M2 = min($W_1[1..n,1..n,1..n]$)\}
        
        Correctness of the algorithm : 
        
        First lets prove loop invariant.
        Its true initially(M2 = min(minW1,W1[1..n,1..n,1..n],since minw1 is initialized as infinity, W1[1..n,1..n,1..n] is definition of M2.
        Now assume its true for l iterations.Using this lets prove it for l+1 iteration,in l+1th iteration we consider all triplets which contain minimum element among remaining elements, among these triplets, the triplet whose elements are minimum elements of each array (i..n,j..n,k..n) is the triplet with best possible answer.This can be proved easily.
        Since all triplets that contain elements less than l+1th smallest element are already considered,now considering this triplet,minW1 also contains minimum of all the triplets that contain l+1th element too.Hence by induction the statement is true.
        \\The terminating condition of the loop is max(i,j,k) = n+1. At terminating condition, the loop invariant will be M2 = min(minW1, min(W1[i+1..n,j+1..n,k+1..n]), but the second term doesn't exist. Therefore, M2 = minW1        
        \item $M_3$ = max \{$W_2(i,j,k)$\} :

        
        To find the three points(belonging to different arrays) such that the distance between the closest two points is the largest among all other pairs.
        
        We check each combination of taking either 2 arrays at a time, \textit{(i.e)} taking (a,b), (b,c), and (c,a) as the upper and lower limits, since to find the maximum of $W_2$, we need to find the three points such that the distance between the 2 closest points need to be the largest, which might not be the case when the lower limit is taken as the min(a[1],b[1],c[1]) and the upper limit as max(a[n],b[n],c[n]), since the element of the other closest to the mean of the upper limit and lower limit, might be far away from the mean 
        \begin{verbatim}
            Assuming the limits as part of arrays 'a' and 'c'
            //similarly with the pairs (a,b) and (b,c)
            Case-1: 
                min = a[1]
                max = c[n]
                while( |a[1]-b[i]| < |c[n]-b[i]| ){
                    i++
                }
                tempMin1 = min(|a[1]-b[i-1]| , |b[i]-c[n]|)
            Case-2:
                min = c[1]
                max = a[n]
                while( |c[1]-b[i]| < |a[n]-b[i]|){
                    i++
                }
                tempMin2 = min(|c[1]-b[i-1]| , |b[i]-c[n]|)
                
            tempM3(c,a) = max(tempMin1, tempMin2)
            M3 = max(tempM3(a,b), tempM3(b,c), tempM3(c,a))
        \end{verbatim}
        \item $M_4$ = min \{$W_2(i,j,k)$\} : 
        
        To find the two closest points(belonging to different arrays) in the set \{[a[1..n], b[1..n], c[1..n]\}, irrespective of the third point
        \begin{verbatim}
            i=1, j=1, k=1
            while(i,j,k <= n){
                W2 = min(|a[i]-b[j]|, |b[j]-c[k]|, |c[k]-a[i]|)
                minW2 = min(minW2, W2)
                minTemp = min(a[i], b[j], c[k])
                if(minTemp == a[i]) i++
                else if(minTemp == b[j]) j++
                else if(minTemp == c[k]) k++
            }
            M4 = minW2
        \end{verbatim}
        Initial conditions ; \{(i=j=k=1) $\cap$ (minW2 = W2[1,1,1])\}
        
        Loop invariants : \{M4 = min(minW2, min(W2[i..n,j..n,k..n]))\}
        
        Final conditions ; \{(M4 = min(W2[1..n,1..n,1..n])) $\cap$ (max(i,j,k) = n+1)\}
        
        Correctness of the algorithm : 
        
        First lets prove loop invariant.
        Initially(M2 = min(minW2,W2[1..n,1..n,1..n],since minw2 is initialized as infinity, W2[1..n,1..n,1..n] is definition of M2.
        Now assume its true for l iterations.Using this lets prove it for l+1 iteration,in l+1th iteration we consider all triplets which contain minimum element among remaining elements, among these triplets, the triplet whose elements are minimum elements of each array (i..n,j..n,k..n) is the triplet with best possible answer.This can be proved easily.
        Since all triplets that contain elements less than l+1th smallest element are already considered,now considering this triplet,minW2 also contains minimum of all the triplets that contain l+1th element too.Hence by induction the statement is true.
        \\The terminating condition of the loop is max(i,j,k) = n+1. At terminating condition, the loop invariant will be M4 = min(minW2, min(W2[i..n,j..n,k..n]), but the second term doesn't exist. Therefore, M4 = minW2
    \end{enumerate}
    \item
    The common element can be found by incriminating the smallest of the set(a[i], b[j], c[k]) one by one, until all three are equal. 2 comparisons will be needed for each increment to find the minimum. Thus, in the worst case scenario, in which the common element is the last element in each array, the total number of comparisons will be :
    \[ \sum_{i=1}^{p}2 +  \sum_{j=1}^{q}2 + \sum_{k=1}^{r}2\]
    Therefore, the time complexity of the program will be of O(p+q+r)
    
    \textbf{Pseudo-code :}
    \begin{verbatim}
        while((i != j) || (j != k)){
            temp = min(a[i],b[j],c[k])
            if(temp == a[i]) i++
            if(temp == b[j]) j++
            if(temp == c[k]) k++
        }
        return (a[i],i,j,k)
    \end{verbatim}
    
    \textbf{EXTRA-1} : 
    The naive algorithm of O($nm^2$) can be obtained by using the first row as reference. For each element in the first row, every other row is checked for whether that element is present in the row. If it is not present in every other row, then check with the next element in the reference row.
    The time complexity will be:
    \[\sum_{i=1}^{m}(n-1)\sum_{j=1}^{m}1 = (n-1)*m^2 \]
    \textbf{Pseudo-code :}
    \begin{verbatim}
        i=1,j=2;k=1
        position[1....n] = 0
        for(i=1;i<=m;i++){
            for(j=2;j<=n;j++){
                for(k=1;k<=m;k++){
                    if(a[1][i] == a[j][k]){
                        position[j] = k
                        break
                    }
                }
                if(k == m+1) break  //a[1][i] isn't present in row j
            }
            if(j == n+1){           //every row contains a[1][i]
                position[1] = i
                return (a[1][position[1]],position)
            }
        }
    \end{verbatim}
    Initial conditions : \{(i=1) $\cap$ (k=1) $\cap$ (j=2) $\cap$ (position[1..n] = 0)\}
    
    Loop invariants : \{(i$\leq$m) $\cap$ (k$\leq$m+1) $\cap$ (j$\leq$n+1) $\cap$ (position[a] $\epsilon$ [0,m])\}
    
    Final conditions ; \{(position[a] $\epsilon$ [1,m]) $\cap$ (j = n+1)\}
    
    \underline{Proof of correctness} :
    
    The loop invariant is valid before the loop initiates. While checking each element in the first row, position[j] might get updated to k, if the kth element of the jth row is equal to the ith element in the first row, but we know that the inner loop terminates when k = m+1. Thus the maximum value position[j] can get is m. Since we know there is a common element, position[j] need not be reset every time 'i' is incremented. When the main loop terminates, j = n+1, (\textit{i.e}) every n values of position has been updated in this loop. Therefore, position[i] will contain the position of the common element in the ith row.  
    
    A more efficient algorithm can be achieved by using an incremental procedure. We compare the least elements in each row. If they are equal, then return the positions and the value. Else, increment all rows except the row with the highest minimum value. Since there exists a common element, continue this until all the minimum elements are equal.The time complexity will be: 
    \[\sum_{i=1}^{m}2*(n-1) = 2m(n-1)\]
    The max of the minimum values can be found with (n-1) comparisons and we will have to increment to the mth value of each row at most, incrementing (n-1) rows at a time. Thus the time complexity of the algorithm is of $O(nm)$.
    
    \textbf{Pseudo-code :}
    \begin{verbatim}
        indices[1...n] = 1
        while(max(indices[...] <= m){
            for(i=1;i<n;i++){
                if(a[i][indices[i]] != a[i+1][indices[i+1]]) break
            }
            if(i == n) break    //found the common element
            maxTemp = a[1][indices[1]]
            for(i=2;i<=n;i++){
                if(maxTemp < a[i][indices[i]]){
                    maxTemp = a[i][indices[i]]
                }
            }
            //for all rows except those containing maxTemp
            for(i=1;i<=n;i++){
                if(a[i][indices[i]] != maxTemp) indices[i] ++
            }
        }
        return (a[i][indices[i]], indices)
    \end{verbatim}
    Initial conditions : \{indices[1..n] = 1\}
    
    Loop invariant : \{(indices[1..n] $\leq$ m) $\cap$ (maxTemp $\leq$ x)\}
    
    Final conditions : \{(a[i][indices[i]] = x $\forall$ i $\epsilon$ [1,n]) $\cap$ (maxTemp = x)\}
    
    \underline{Proof of correctness} :
    
    We know that a common element, x exists. A terminating condition for the loop is for maxTemp to be equal to x. If the current element of a row is x, then the the indices of all other rows will be increased till the point the element in each row is x, since all the rows contain x and thus, the new value of the row element can't be greater than x, without the row element reaching x. Since the maxTemp is also x, the index of this row won't be incremented. We can prove that the current element of some row will be x at some point. Assume that x hasn't appeared in any row yet. Thus maxTemp is less than x, so if some row does reach x, it's index will not be incremented the next iteration. We can also say that x will not be skipped in a row, since maxTemp is less than or equal to x, and for x to be skipped, maxTemp should be greater than x. So, if x hasn't appeared in one row, it hasn't been skipped in any other row. Since x is present in all rows, the index of a row can't cross m+1 without reaching x, and since maxTemp won't be larger than x till the point some row reaches x, the current element of a row will be x at one point of time.
    
    \textbf{EXTRA-2}: 
    
    For the naive algorithm of $O(nm^2)$, the only additional condition will be if i=m+1, the there will be no common element.
    
    \textbf{Pseudo-code :}
    \begin{verbatim}
        i=1,j=2;k=1
        position[1....n] = 0
        for(i=1;i<=m;i++){
            for(j=2;j<=n;j++){
                for(k=1;k<=m;k++){
                    if(a[1][i] == a[j][k]){
                        position[j] = k
                        break
                    }
                }
                if(k == m+1) break  //a[1][i] isn't present in row j
            }
            if(j == n+1){           //every row contains a[1][i]
                position[1] = i
                return (a[1][position[1]], position)
            }
        }
        return (-1) // since there in no common element
    \end{verbatim}
     Initial conditions : \{(i=1) $\cap$ (k=1) $\cap$ (j=2) $\cap$ (position[1..n] = 0)\}
    
    Loop invariants : \{(i$\leq$m+1) $\cap$ (k$\leq$m+1) $\cap$ (j$\leq$n+1) $\cap$ (position[a] $\epsilon$ [0,m])\}
    
    Final conditions ; \{((position[a] $\epsilon$ [1,m]) $\cap$ (j = n+1)) $\cup$ (i = m+1)\}    
    
    For the incremental algorithm of $O(nm)$
    
    \textbf{Pseudo-code :}
    \begin{verbatim}
        indices[1...n] = 1
        while(max(indices[...] <= m){
            for(i=1;i<n;i++){
                if(a[i][indices[i]] != a[i+1][indices[i+1]]) break
            }
            if(i == n) break    //found the common element
            maxTemp = a[1][indices[1]]
            for(i=2;i<=n;i++){
                if(maxTemp < a[i][indices[i]]){
                    maxTemp = a[i][indices[i]]
                }
            }
            //for all rows except those containing maxTemp
            for(i=1;i<=n;i++){
                if(a[i][indices[i]] != maxTemp) indices[i] ++
            }
        }
        if(i == n) return (a[i][indices[i]], indices)
        else return(-1)
    \end{verbatim}
    Initial conditions : \{indices[1..n] = 1\}
    
    Loop invariant : \{(indices[1..n] $\leq$ m+1)\}
    
    Final conditions : \{(a[i][indices[i]] = a[i+1][indices[i+1]] $\forall$ i $\epsilon$ [1,n-1]) $\cup$ (max[indices[1..n] = m+1)\}
    \item[8.]
    \begin{enumerate}
        \item Let $S_i(x) = \prod_{i\neq j,1 \leq j \leq n} \frac{x-x_j}{x_i-x_j}$
Now,We can see that $S_i(x_j)$ is 0 if $i \neq j$ and 1 if $i = j$.This is because if $i \neq j$, there is $x-x_j$ as a factor of $S_i(x)$ so its value becomes 0.If i = j then after substituting $x_i$ in x, every factor in numerator gets cancelled with denominator giving 1.
So this $S_i(x)$ is similar to Kronecker delta function.
\begin{equation*}
    S_i(x_j) = \delta_{ij}
\end{equation*}
Now our polynomial A(x) is linear combination of $S_i(x)$ for $1 \leq i \leq n$.
\begin{equation*}
    A(x) = \sum_{1 \leq i \leq n}{y_i S_i(x)}
\end{equation*}
So for any $x_i(1 \leq i \leq n) , A(x_i) = y_i S_i(x_i)$.But $S_i(x_i)=1$, so $A(x_i)=y_i$.Hence
the polynomial A(x) satisfies all n points.
\item
The naive algorithm calculates each $S_i$ individually.To compute each $S_i$, The numerator is a polynomial and requires $O(n^2)$ steps to compute its coefficients naively.Once numerator is known denominator can be computed using Horner's method in O(n) or just subtract and multiply n-1 times which is also in O(n) steps.So the overall complexity is $O(n^3)$ because each $S_i$ takes $O(n^2)$ steps.
Now calculation of numerator:
Assume numerator has roots $a_1,a_2....a_n-1$ where these $a_i$s' are $x_i$ where one $x_i$ is missing.Lets use an incremental algorithm where we have polynomial with roots $a_1,a_2....a_k$(let it be $P_{k}(x)$ already and we have to add $a_{k+1}$ as root to get $P_{k+1}(x)$.Let coefficients of $P_k(x)$ be in array p where p[i] is coefficient of $x^i$ and coefficients of $P_{k+1}(x)$ be in array q, where q[i] is coefficient of $x^i$.Now following pseudo code will get q from p:
    \begin{verbatim}
    q[0] = -p[0] * a[k]; //a[k] is k+1 th root
    for(int i = 1;i <= k;i++)
    {
        q[i] = p[i-1] - p[i]*a[k];
    }
    q[k+1] = 1;
    \end{verbatim}
Starting with polynomial 1,we can keep on adding $a_i$s as roots and achieve the final polynomial using above code.This takes 2k steps for kth root,now for computing $S_i$ this 2k is to be summed over 1,2,....n-1 which is (n-1)*n steps for each $S_i$.Now the total number of steps = n*(n-1)*n which is $O(n^3)$.
\item
We use two recurrence relations:
\begin{equation*}
D_j(x) = D_{j-1}(x) *(x - x_{j})
\end{equation*}
and 
\begin{equation*}
G_j(x) = (y_j - G_{j-1}(x_j)) \frac{D_{j-1}(x)}{D_{j-1}(x_j)} + G_{j-1}(x)
\end{equation*}
with base cases $D_0(x) = 1$ and $G_0(x) = 0$.
Now all $D_j$s' can be calculated in $O(n^2)$ from 8-b.Now each $G_{j-1}(x_j)$ takes 2j steps using Horner's method,Similarly $D_{j-1}$ takes 2j steps and addition of coefficients after multiplying also take linear steps in j.
So each $G_j(x)$ takes c*j steps. So to calculate $G_n(x)$ we do c*1 + c*2 +.....c*n = c *n*(n+1)/2 steps. So the order becomes $O(n^2)$.
\end{enumerate}
 \item[7.]
    Along with the relations used in 8-c we also use two additional equations:
    \begin{equation*}
        D_j'(x) = D_{j-1}'(x) * (x-x_j) + D_{j-1}(x).
    \end{equation*}
    \begin{equation*}
        G_j'(x) = (y_j - G_{j-1}(x_j)) \frac{D_{j-1}'(x)}{D_{j-1}(x_j)} + G_{j-1}'(x)
    \end{equation*}
    with base cases $G_0'(x) = 0$ and $D_0'(x) = 0$.
    The order of computation would be finding $D_j(x)$ first then $D_j'(x)$ and then $G_j(x)$ and finally $G_j'(x)$ in a single loop run.
    Now computing all these at jth point is again linear in j(similar to 8). so again the total number of steps is c*1 + c*2 + ...c*n = c*n(n+1)/2 which is again $O(n^2)$
    \item[9.]
    Let G(n) be minimum number of calls they have to make so that all n people receive every information.The best bound on G(n) we could find is $G(n) \leq 2n - 4, \forall n \geq 4$.
    \\Proof:
    Lets prove it by induction,
    \\Base case:
    For n = 4, and let people be named a,b,c,d.Now the following is solution in 4 steps:
    a calls b, c calls d , a calls c ,b calls d.
    We can see that in these 4 calls every information is reached to all.
    \\Now assume for $k \geq 4$ assume that $G(k) \leq 2k - 4$, (Inductive Hypothesis) , lets prove its true for k+1 using k.
    \\Consider sequence of calls corresponding to solution G(k), Now to these sequence of calls, add
    $(k+1)^{th}$ guy calling some other guy from k people (say a) as the first call.Now since a's information is transferred to all other k-1 people so will be k+1's information.Now add a call again from a random person of k people to k+1 to the end of sequence.Since after all calls every one of k people have all the information,making this call will make k+1 also know all information.\\So, $G(k+1) \leq 2k-4+1+2$(since there exists a solution using k for k + 1 ,G(k+1) must be less than or equal to this).
    \\$G(k+1) \leq 2k-2$.\\$G(k+1) \leq 2(k+1) -4$.
    So by Induction,It is true $\forall k \geq 4$.
\end{enumerate}
\begin{enumerate}
    \item[22.4-2/32.3.] The number of paths from one node to another in a DAG can be found in linear time, \textit{(i.e)} in O(n+m), using the dfs algorithm. We maintain two arrays of size n, storing the number of paths from that node to the destination node, and another , stating whether the node has already been visited in the dfs traversal. Here, a node is said to be visited, if the dfs call of that node has initiated or had completed.
    
    \textbf{Pseudo-code :}
    \begin{verbatim}
        int NumPaths(vertex start, vertex end, int* numPaths, bool* isVisited){
            int sum = 0
            isVisited[start] = true
            for(v in adjacencyList[start]){
                if(v == end) sum++
                else if(isVisited[v] == true) sum += numPaths[v]
                else sum += NumPaths(v, end, numPaths, isVisited)
            }
            numPaths[start] = sum
            return (sum)
        }
    \end{verbatim}
    \item[3.24.] Sort the vertices topologically. So, now in the topologically sorted order we have all the edges directed to one side, without loss of generality we can assume right. 
    
    In a graph G, if it has to contain a directed path passing through every vertex then there must be an edge connecting all adjacent vertices in the topologically sorted order.
    
    \textbf{Proof:-}
    
    Suppose there is a directed path P which is passing through all the vertices in G but does not follow the above property.Let the graph G contain n vertices 
    
    Let us assume the topologically sorted order of vertices is given by toposort[0..(n-1)]
    
    Suppose there is no edge between toposort[i] $(i\neq(n-1))$ and toposort[i+1]. But since P is passing through all the vertices there exists a path P' from toposort[i] to toposort[i+1]. 
    
    \underline{Case1 }:
    Let us assume the immediate vertex in P' after toposort[i] be toposort[j], $j>i$ and $j\neq(i+1)$ . 
    
    \[ \Rightarrow P' = ( toposort[i],toposort[j],...,toposort[i+1] )  \]
    
    But this is not possible since P' can not go from toposort[j] to toposort[i+1] since j $>$ (i+1) there can not be any backward edges as the vertices are in topological order.
    
    \underline{Case2 }:
    There are no intermediate vertices in P' \textit{(i.e)} P' = {toposort[i],toposort[i+1]}, but this is clearly a contradiction since we have assumed there is no edge between toposort[i],toposort[i+1].
    
    \textbf{Time complexity :-}
    
    If the graph is represented using adjacency list, the topological sorting of the vertices take O(V+E) time since it performs a DFS. After the topological sorting, for checking if there is an edge between every adjacent vertex takes O(V+E) time. The overall time is O(V+E)
    
    If the graph is represented using matrix then topological sort would take O($V^2$) and checking the edge between adjacent vertex would take O(V). But the overall time complexity is O($V^2$), which is not linear. 
    
    Hence, adjacency list representation must be used. 
    
    So the overall time = O(V+E)
    \item[3.25.]
    \begin{enumerate}
        \item 
        For a Directed acyclic graph, we find topological sort using DFS which takes O(V+E).In topological sort, for a given vertex, all vertices reachable by it are to the right of it.
        So, we process vertices in reverse topological order, and for every vertex(u) we find minimum of cost[v] for all adjacent vertices v to the current vertex(u)(including current vertex's price) and assign cost[u] this minimum value.Since we are doing it in reverse topological order cost[v] would have already been calculated.
       \\ \textbf{Pseudo code :}
        \begin{verbatim}
            void findCost(int x)
            {
                cost[x] = price[x];
                for(int &i:adjList[x])
                {
                    cost[x] = min(cost[x],cost[i]);
                }
            }
            int main()
            {
                for(int i = n-1; i >= 0; i--)
                {
                    findCost(topoSort[i]);
                }
            }
        \end{verbatim}
        \textbf{Time Complexity:}
        Time complexity of this is O(V+E), Finding topological sort takes O(V+E) time and finding cost also takes O(V+E) time(because \emph{findCost} is called V times and total number of times minimum function is called is E).So overall time complexity is O(V+E).
        \item
        The two-tiered structure of directed graph is that every directed graph can be represented as Directed Acyclic graph with Strongly Connected Components(SCC) as its vertices.
        Now, this is useful because in our case, for a SCC all vertices in it have same cost which is minimum of price of each vertex in SCC(because every vertex is reachable by every other vertex in it). And across SCCs' the cost behaves similar to DAG.
        The algorithm for general directed graph goes as follows:\\
        1)Find strongly connected components in the graph using Kosaraju's algorithm in linear time(O(V+E)).\\
        2)Create a new graph G' whose vertices are SCC's of our original graph(G).\\
        3)The price of a vertex in this graph is minimum of prices of all vertices in original graph that belong to this SCC.\\
        4)Now edges of G' is all edges of G, such that ends of that edge in G is corresponding SCC in G',Remove self loops,i.e ignore edges among vertices in same SCC.This may create parallel edges but they wont be a problem.\\
        5)Find Cost array of G' using algorithm in part (a) since its a DAG.\\
        6)Now cost array of original graph is calculated using this cost array where for each vertex, its cost is equal to the cost of SCC it belongs to.\\
        This whole algorithm can be implemented as follows:
        After step 1, for each SCC assign an index to represent it in G' and store an array of length |V| named SCC where SCC[u] contains index of SCC the vertex u belongs to.
        Also create a price array(say price1) of length = number of SCCs.Initialize them with $\infty$ and do the following to assign their prices.
        \begin{verbatim}
            for(int i = 0; i < n; i++)
            {
                int x = SCC[i];
                price1[x] = min(price1[x],price[i]);
            }
        \end{verbatim}
        Now coming to edges,edges of G' can be created as follows:
        \begin{verbatim}
            for(int i = 0; i < n; i++)
            {
                for(int &x:adjList[i])
                {  if(SCC[i]!=SCC[x])
                    adjList1[SCC[i]].insert_at_end(SCC[x]);
                }
            }
        \end{verbatim}
        Now we get Adjacency list of G' in adjList1.Now that we have adjList1,price1, we can get cost1 ,cost array of G' using algortithm from part a.\\
        Now cost array of original can be retrieved as
        \begin{verbatim}
        for(int i = 0; i < n; i++)
        {
            cost[i] = cost1[SCC[i]];
        }
        \end{verbatim}
        \textbf{Time Complexity:}
        Step 1 takes O(V+E),creating price array takes O(V),creating adjacency list for G' takes O(V+E),now number of vertices in G' is bounded V and edges also bounded by E,so finding cost1 takes O(V+E), from cost1 finding cost array takes O(V).\\
        So overall complexity is O(V+E).
        
    \end{enumerate}
\end{enumerate}
\end{document}
